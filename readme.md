## ğŸ“ Proyecto: AI-Prompt-Validator  

### ğŸ“Œ **Objetivo del Proyecto**  

El objetivo de este proyecto es diseÃ±ar un **sistema que valide y corrija los prompts antes de enviarlos a la IA**. Esto ayuda a optimizar las respuestas generadas, asegurando que sean **claras, conformes y libres de riesgos potenciales** (por ejemplo, sesgo, lenguaje daÃ±ino o datos sensibles).  

Para lograr esto, configuramos diferentes servicios en **Azure** y creamos una **arquitectura backend** basada en **Azure Functions** y **Azure OpenAI**.  

---

## âš™ï¸ **ConfiguraciÃ³n Paso a Paso**  

### 1ï¸âƒ£ **Crear Azure Function App**  
ğŸ’¡ **FunciÃ³n principal donde correrÃ¡ nuestra validaciÃ³n.**  

1. Ir al **Portal de Azure** [ğŸ”— Azure Portal](https://portal.azure.com).  
2. En la barra de bÃºsqueda, escribir **Function App** Ã³ **Aplicacion de Funcion** si estÃ¡ en espaÃ±ol y hacer clic en **"Crear"**.  

**Nota:** en caso que la barra de <u>Marketplace</u> no lo encuentre usar este link luego de loguearse:  
```
https://portal.azure.com/#view/HubsExtension/BrowseResource/resourceType/Microsoft.Web%2Fsites/kind/functionapp
```
3. Configurar los siguientes valores:  
   - **SuscripciÃ³n:** Seleccionar la suscripciÃ³n activa.  
   - **Grupo de recursos:** **AI-Prompt-Validator-RG** (si no existe, crearlo).  
   - **Nombre de la Function App:** **prompt-validator-function**.  
   - **RegiÃ³n:** **East US 2**.  
   - **Pila de tiempo de ejecuciÃ³n:** **Python 3.10**.  
   - **TamaÃ±o de instancia:** **2048 MB** (para optimizar costos).  
4. En la pestaÃ±a **Monitoreo**, seleccionar:  
   - **Habilitar Application Insights:** **SÃ­**.  
   - **Application Insights Resource:** **prompt-validator-function-openai-b083** (creado automÃ¡ticamente).  
5. Hacer clic en **"Revisar y Crear"** â†’ **"Crear"** y esperar la implementaciÃ³n.  

---

### 2ï¸âƒ£ **Habilitar Azure OpenAI**  
ğŸ’¡ **Este servicio procesarÃ¡ las correcciones y validaciones de los prompts.**  

1. En el Portal de Azure, buscar **"Azure OpenAI"**.  
2. Hacer clic en **"Habilitar Azure OpenAI"**.  
3. Configurar los siguientes valores:  
   - **RegiÃ³n:** **East US 2** (misma que Function App).  
   - **Recurso creado:** **prompt-validator-function-openai-b083**.  
   - **Almacenamiento vectorial:** Seleccionar **"Configurar mÃ¡s tarde"**.  
4. Hacer clic en **"Revisar y Crear"** â†’ **"Crear"** y esperar la implementaciÃ³n.  

---

### 3ï¸âƒ£ **Configurar Azure Cognitive Services - Language Service**  
ğŸ’¡ **Este servicio nos permitirÃ¡ corregir la gramÃ¡tica y optimizar el texto.**  

1. En el Portal de Azure, buscar **"Language Service"**.  
2. Hacer clic en **"Crear"**.  
3. Configurar los siguientes valores:  
   - **SuscripciÃ³n:** Seleccionar la suscripciÃ³n activa.  
   - **Grupo de recursos:** **AI-Prompt-Validator-RG**.  
   - **Nombre del servicio:** **prompt-language-service**.  
   - **RegiÃ³n:** **East US 2**.  
   - **Plan de tarifa:** **S (Standard, 1K llamadas/minuto)**.  
4. Hacer clic en **"Revisar y Crear"** â†’ **"Crear"** y esperar la implementaciÃ³n.  

---

### 4ï¸âƒ£ **Obtener las Claves y Endpoint de los Servicios**  
ğŸ’¡ **Necesitamos estas credenciales para integrarlas en nuestro cÃ³digo.**  

ğŸ“Œ **Para Azure OpenAI:**  
1. Ir a **Azure OpenAI** â†’ **prompt-validator-function-openai-b083**.  
2. En el menÃº lateral, hacer clic en **"Keys and Endpoint"**.  
3. Copiar:  
   - **Endpoint:** `https://turecurso.openai.azure.com/`  
   - **Key:** `tu-clave-de-openai`  

ğŸ“Œ **Para Azure Cognitive Services - Language Service:**  
1. Ir a **Language Service** â†’ **prompt-language-service**.  
2. En el menÃº lateral, hacer clic en **"Keys and Endpoint"**.  
3. Copiar:  
   - **Endpoint:** `https://turecurso.cognitiveservices.azure.com/`  
   - **Key:** `tu-clave-de-cognitive-services`  

---

### 5ï¸âƒ£ **Actualizar el archivo `local.settings.json` en Azure Functions**  
ğŸ’¡ **Para que nuestra funciÃ³n use las credenciales correctas.**  

1. Abrir el proyecto en **Visual Studio Code**.  
2. Dentro de la carpeta de Azure Functions, localizar **`local.settings.json`**.  
3. Reemplazar el contenido con las credenciales copiadas:  

```json
{
  "IsEncrypted": false,
  "Values": {
   ...
    "CONTENT_SAFETY_ENDPOINT": "https://turecurso.cognitiveservices.azure.com/",
    "CONTENT_SAFETY_KEY": "tu-clave-de-content-safety"
   ...
  }
}
```

DespuÃ©s de haber configurado los servicios base en Azure, ahora hemos **implementado los modelos en Azure OpenAI** y actualizado nuestra funciÃ³n en Azure Functions para conectarse correctamente con estos recursos.  

---

## âš™ï¸ **5ï¸âƒ£ ImplementaciÃ³n de Modelos en Azure OpenAI**  

ğŸ’¡ Para validar y generar respuestas optimizadas, implementamos **GPT-35-Turbo** en **Azure AI Foundry** con dos configuraciones:  

1. **CorrecciÃ³n de Prompts** â†’ `corrector-deployment`.  
2. **GeneraciÃ³n de Respuestas** â†’ `respuesta-deployment`.  

ğŸ“Œ **Pasos seguidos:**  

1. Entramos en **Azure AI Foundry** desde el **Portal de Azure**.  
2. En la pestaÃ±a **Implementaciones**, hicimos clic en **"Nueva implementaciÃ³n"**.  
3. **Configuramos cada implementaciÃ³n** con:  
   - **Modelo:** `gpt-35-turbo`.  
   - **Tipo de implementaciÃ³n:** `EstÃ¡ndar`.  
   - **VersiÃ³n del modelo:** `0125` (Ãºltima estable).  
   - **Filtro de contenido:** `DefaultV2`.  
   - **Cuota dinÃ¡mica:** **Activada**.  
   - **Tokens por minuto (TPM):** **Reducido a 10K** (para evitar problemas de cuota).  
4. Esperamos la activaciÃ³n y verificamos que ambas implementaciones aparezcan en la lista de **Implementaciones Activas**.  

---

## ğŸ”‘ **6ï¸âƒ£ ObtenciÃ³n de Credenciales de Azure OpenAI**  

DespuÃ©s de implementar los modelos, **obtenemos las claves y el endpoint** para integrarlos en nuestro backend.  

ğŸ“Œ **Pasos seguidos:**  

1. En el **Portal de Azure**, buscamos el recurso **`prompt-validator-function-openai-b083`**.  
2. Hicimos clic en **"Click here to view endpoints"** y copiamos la URL del endpoint.  
3. Hicimos clic en **"Click here to manage keys"** y copiamos la **Key 1**.  

ğŸ“Œ **Ejemplo de credenciales obtenidas:**  
- **Endpoint:** `https://turecurso.openai.azure.com/`  
- **Key:** `tu-clave-de-openai`  

---

## ğŸ›  **7ï¸âƒ£ ConfiguraciÃ³n de Azure Functions (`local.settings.json`)**  

Ahora, actualizamos **Azure Functions** para conectar correctamente OpenAI con nuestra API.  

ğŸ“Œ **Pasos seguidos:**  

1. Abrimos el proyecto en **Visual Studio Code**.  
2. Modificamos el archivo **`local.settings.json`** para incluir las claves y endpoints de OpenAI.  

ğŸ“Œ **Ejemplo de `local.settings.json` actualizado:**  

```json
{
  "IsEncrypted": false,
  "Values": {
   ...
    "OPENAI_ENDPOINT": "https://turecurso.openai.azure.com/",#-> AquÃ­ colocamos el Endpoint
    "OPENAI_KEY": "tu-clave-de-openai",#-> AquÃ­ colocamos la KEY 1
    "OPENAI_CORRECTOR_DEPLOYMENT": "corrector-deployment",
    "OPENAI_RESPUESTA_DEPLOYMENT": "respuesta-deployment",
   ...
  }
}
```

## ğŸ“Œ **8ï¸âƒ£ VerificaciÃ³n en Azure Functions**  

Antes de continuar con el desarrollo del backend, verificamos que **Azure Functions estÃ© correctamente configurado**.  

ğŸ“Œ **Pasos seguidos:**  

1. Entramos a **Azure Functions** en el **Portal de Azure**.  
2. Buscamos nuestra funciÃ³n **`prompt-validator-function`**.  
3. En el menÃº lateral, fuimos a **ConfiguraciÃ³n > Variables de AplicaciÃ³n**.  
4. **Verificamos que las claves y endpoints de OpenAI y Cognitive Services estÃ©n correctamente cargados.**  

ğŸš€ **Con esto, Azure Functions ya estÃ¡ listo para conectarse con OpenAI.**  

---

## ğŸ¯ **PrÃ³ximos Pasos**  

âœ… **Implementar los endpoints `/api/validatePrompt` y `/api/generateResponse` en Azure Functions.**  
âœ… **Realizar pruebas iniciales para validar la comunicaciÃ³n con OpenAI.**  
âœ… **Optimizar el flujo de correcciÃ³n de prompts antes de enviar las solicitudes a la IA.**  



