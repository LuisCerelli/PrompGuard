{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pxc0Iw4Xofk",
        "outputId": "1f148236-5495-49e2-b556-339d73a9bd65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: azure-functions in /usr/local/lib/python3.11/dist-packages (1.21.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.61.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
            "Requirement already satisfied: azure-ai-contentsafety in /usr/local/lib/python3.11/dist-packages (1.0.0)\n",
            "Requirement already satisfied: isodate<1.0.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from azure-ai-contentsafety) (0.7.2)\n",
            "Requirement already satisfied: azure-core<2.0.0,>=1.28.0 in /usr/local/lib/python3.11/dist-packages (from azure-ai-contentsafety) (1.32.0)\n",
            "Requirement already satisfied: requests>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from azure-core<2.0.0,>=1.28.0->azure-ai-contentsafety) (2.32.3)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from azure-core<2.0.0,>=1.28.0->azure-ai-contentsafety) (1.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from azure-core<2.0.0,>=1.28.0->azure-ai-contentsafety) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.28.0->azure-ai-contentsafety) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.28.0->azure-ai-contentsafety) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.28.0->azure-ai-contentsafety) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.28.0->azure-ai-contentsafety) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "!pip install requests azure-functions\n",
        "!pip install openai\n",
        "!pip install azure-ai-contentsafety"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PfwRE-urGepr"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "import logging\n",
        "import azure.functions as func\n",
        "\n",
        "from azure.core.credentials import AzureKeyCredential\n",
        "from azure.ai.textanalytics import TextAnalyticsClient\n",
        "\n",
        "from openai import AzureOpenAI\n",
        "\n",
        "from azure.ai.contentsafety import ContentSafetyClient\n",
        "from azure.core.credentials import AzureKeyCredential\n",
        "from azure.core.exceptions import HttpResponseError\n",
        "from azure.ai.contentsafety.models import AnalyzeTextOptions, TextCategory\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dDRGlcXBU25k"
      },
      "outputs": [],
      "source": [
        "# Variables de entorno con las claves de los servicios\n",
        "AZURE_LANGUAGE_API_URL = ''  # Cambiar <tu-endpoint> al URL correcto de tu recurso\n",
        "AZURE_LANGUAGE_API_KEY = ''  # Cambia por tu clave de suscripci√≥n\n",
        "\n",
        "AZURE_OPENAI_API_URL = ''  # Cambiar <tu-endpoint-openai>\n",
        "AZURE_OPENAI_API_KEY = ''  # Cambiar clave de OpenAI\n",
        "\n",
        "AZURE_CONTENT_SAFETY_API_URL = ''\n",
        "AZURE_CONTENT_SAFETY_API_KEY = ''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "eXayfVo4GfYr"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Funci√≥n para analizar texto con Azure Language\n",
        "def analyze_text(prompt):\n",
        "    \"\"\" Analiza el texto usando Azure Language Services. \"\"\"\n",
        "    try:\n",
        "        text_analytics_client = TextAnalyticsClient(endpoint=AZURE_LANGUAGE_API_URL, credential=AzureKeyCredential(AZURE_LANGUAGE_API_KEY))\n",
        "        response = text_analytics_client.recognize_entities(documents=[prompt])\n",
        "\n",
        "        if response:\n",
        "            return response\n",
        "        else:\n",
        "            logging.error(\"Error en la API: No se recibieron datos.\")\n",
        "            return {\"error\": \"No se recibieron datos de la API.\"}\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error en la API: {str(e)}\")\n",
        "        return {\"error\": f\"Fall√≥ la solicitud: {str(e)}\"}\n",
        "\n",
        "# Uso de Azure OpenAI para reescribir texto\n",
        "def rewrite_prompt_with_openai(prompt):\n",
        "    endpoint = AZURE_OPENAI_API_URL\n",
        "    model_name = \"gpt-35-turbo\"\n",
        "    deployment = \"gpt-35-turbo\"\n",
        "    subscription_key = AZURE_OPENAI_API_KEY\n",
        "    api_version = \"2024-12-01-preview\"\n",
        "\n",
        "    client = AzureOpenAI(\n",
        "        api_version=api_version,\n",
        "        azure_endpoint=endpoint,\n",
        "        #azure_ad_token_provider=token_provider,\n",
        "        api_key=subscription_key,\n",
        "    )\n",
        "\n",
        "    # Solicitud de reescritura de texto\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"Corrige la gram√°tica del siguiente texto y mejora su claridad.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            max_tokens=4096,\n",
        "            temperature=1.0,\n",
        "            top_p=1.0,\n",
        "            model=deployment\n",
        "        )\n",
        "        return response.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error en OpenAI API: {str(e)}\")\n",
        "        return {\"error\": f\"Fall√≥ la solicitud: {str(e)}\"}\n",
        "\n",
        "# Verificaci√≥n de seguridad de contenido\n",
        "def check_content_safety(prompt):\n",
        "    \"\"\" Eval√∫a contenido potencialmente da√±ino con Azure Content Safety. \"\"\"\n",
        "    # analyze text\n",
        "    key = AZURE_CONTENT_SAFETY_API_KEY\n",
        "    endpoint =  AZURE_CONTENT_SAFETY_API_URL\n",
        "\n",
        "    # Create an Azure AI Content Safety client\n",
        "    client = ContentSafetyClient(endpoint, AzureKeyCredential(key))\n",
        "\n",
        "    # Contruct request\n",
        "    request = AnalyzeTextOptions(text=prompt)\n",
        "\n",
        "    # Analyze text\n",
        "    try:\n",
        "        response = client.analyze_text(request)\n",
        "    except HttpResponseError as e:\n",
        "        print(\"Analyze text failed.\")\n",
        "        if e.error:\n",
        "            print(f\"Error code: {e.error.code}\")\n",
        "            print(f\"Error message: {e.error.message}\")\n",
        "            raise\n",
        "        print(e)\n",
        "        raise\n",
        "\n",
        "    hate_result = next(item for item in response.categories_analysis if item.category == TextCategory.HATE)\n",
        "    self_harm_result = next(item for item in response.categories_analysis if item.category == TextCategory.SELF_HARM)\n",
        "    sexual_result = next(item for item in response.categories_analysis if item.category == TextCategory.SEXUAL)\n",
        "    violence_result = next(item for item in response.categories_analysis if item.category == TextCategory.VIOLENCE)\n",
        "\n",
        "    if hate_result:\n",
        "        print(f\"Hate severity: {hate_result.severity}\")\n",
        "    if self_harm_result:\n",
        "        print(f\"SelfHarm severity: {self_harm_result.severity}\")\n",
        "    if sexual_result:\n",
        "        print(f\"Sexual severity: {sexual_result.severity}\")\n",
        "    if violence_result:\n",
        "        print(f\"Violence severity: {violence_result.severity}\")\n",
        "\n",
        "# Funci√≥n principal\n",
        "def main(req: func.HttpRequest) -> func.HttpResponse:\n",
        "    \"\"\" Procesa un prompt y lo analiza con los servicios de Azure. \"\"\"\n",
        "    logging.info(\"Procesando solicitud...\")\n",
        "\n",
        "    try:\n",
        "        req_body = req.get_json()\n",
        "        prompt = req_body.get(\"prompt\", \"\")\n",
        "\n",
        "        if not prompt:\n",
        "            return func.HttpResponse(\"Falta el par√°metro 'prompt'\", status_code=400)\n",
        "\n",
        "        # 1. An√°lisis de texto\n",
        "        analysis_result = analyze_text(prompt)\n",
        "\n",
        "        # 2. Reescribir texto\n",
        "        corrected_prompt = rewrite_prompt_with_openai(prompt)\n",
        "\n",
        "        # 3. Evaluaci√≥n de contenido\n",
        "        safety_result = check_content_safety(corrected_prompt)\n",
        "\n",
        "        # Respuesta final\n",
        "        response_data = {\n",
        "            \"originalPrompt\": prompt,\n",
        "            \"correctedPrompt\": corrected_prompt,\n",
        "            \"textAnalysis\": analysis_result,\n",
        "            \"contentSafety\": safety_result\n",
        "        }\n",
        "\n",
        "        return func.HttpResponse(\n",
        "            body=json.dumps(response_data, indent=2),\n",
        "            mimetype=\"application/json\",\n",
        "            status_code=200\n",
        "        )\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error en el procesamiento: {str(e)}\")\n",
        "        return func.HttpResponse(f\"Error interno: {str(e)}\", status_code=500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5x1qHbrGkN6",
        "outputId": "9add75d8-876f-4a94-c634-ec11f3fc03fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Prompt de prueba: Hola, este texto necdesita ser analizado y mejorado.\n",
            "\n",
            "üîç 1Ô∏è‚É£ Analizando texto...\n",
            "[RecognizeEntitiesResult(id=0, entities=[CategorizedEntity(text=analizado, category=Skill, subcategory=None, length=9, offset=31, confidence_score=0.66)], warnings=[], statistics=None, is_error=False, kind=EntityRecognition)]\n",
            "\n",
            "‚úçÔ∏è 2Ô∏è‚É£ Reescribiendo el prompt...\n",
            "Hola, este texto necesita ser analizado y mejorado.\n",
            "\n",
            "üõ° 3Ô∏è‚É£ Evaluando seguridad del contenido...\n",
            "Hate severity: 0\n",
            "SelfHarm severity: 0\n",
            "Sexual severity: 0\n",
            "Violence severity: 0\n",
            "None\n",
            "\n",
            "‚úÖ 4Ô∏è‚É£ Respuesta final:\n",
            "{'originalPrompt': 'Hola, este texto necdesita ser analizado y mejorado.', 'correctedPrompt': 'Hola, este texto necesita ser analizado y mejorado.', 'textAnalysis': [RecognizeEntitiesResult(id=0, entities=[CategorizedEntity(text=analizado, category=Skill, subcategory=None, length=9, offset=31, confidence_score=0.66)], warnings=[], statistics=None, is_error=False, kind=EntityRecognition)], 'contentSafety': None}\n"
          ]
        }
      ],
      "source": [
        "#Funcion de prueba para validar las conexiones\n",
        "def test_function():\n",
        "    \"\"\"Realiza una prueba b√°sica de las funcionalidades implementadas.\"\"\"\n",
        "    # Prompt de prueba\n",
        "    prompt = \"Hola, este texto necdesita ser analizado y mejorado.\"\n",
        "    print(f\"\\nPrompt de prueba: {prompt}\")\n",
        "    # 1Ô∏è‚É£ An√°lisis de texto\n",
        "    print(\"\\nüîç 1Ô∏è‚É£ Analizando texto...\")\n",
        "    #prompt = \"Tu texto aqu√≠\"  # Aseg√∫rate de definir el texto que deseas analizar\n",
        "    analysis_result = analyze_text(prompt)\n",
        "    print(analysis_result)\n",
        "    #print(json.dumps(analysis_result, indent=2))\n",
        "\n",
        "    # 2Ô∏è‚É£ Reescritura del texto\n",
        "    print(\"\\n‚úçÔ∏è 2Ô∏è‚É£ Reescribiendo el prompt...\")\n",
        "    corrected_prompt = rewrite_prompt_with_openai(prompt)\n",
        "    print(corrected_prompt)\n",
        "\n",
        "    # 3Ô∏è‚É£ Evaluaci√≥n de seguridad del contenido\n",
        "    print(\"\\nüõ° 3Ô∏è‚É£ Evaluando seguridad del contenido...\")\n",
        "    safety_result = check_content_safety(corrected_prompt)\n",
        "    print(safety_result)\n",
        "    #print(json.dumps(safety_result, indent=2))\n",
        "\n",
        "    # 4Ô∏è‚É£ Respuesta final\n",
        "    print(\"\\n‚úÖ 4Ô∏è‚É£ Respuesta final:\")\n",
        "    response_data = {\n",
        "        \"originalPrompt\": prompt,\n",
        "        \"correctedPrompt\": corrected_prompt,\n",
        "        \"textAnalysis\": analysis_result,\n",
        "        \"contentSafety\": safety_result\n",
        "    }\n",
        "    print(response_data)\n",
        "\n",
        "# Llama a la funci√≥n\n",
        "test_function()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
